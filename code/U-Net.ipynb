{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from PIL import Image \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score\n",
       "0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0\n",
       "1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0\n",
       "2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels = pd.read_csv(PATH/'train_labels.csv')\n",
    "test = pd.read_csv(PATH/'test.csv')\n",
    "labels = pd.read_csv(PATH/'train_labels_clean.csv')\n",
    "labels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(labels['image_id'].values, \n",
    "                                                  labels['isup_grade'].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    '''return array representing image'''\n",
    "    return skimage.io.imread(PATH/f'train/{filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_bw(filename):\n",
    "    image_file = Image.open(PATH/f'train/{filename}') # open colour image\n",
    "    image_file = image_file.convert('1') # convert image to black and white\n",
    "    return image_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(filename):\n",
    "    return skimage.io.imread(PATH/f'masks/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PANDADataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        files = []\n",
    "        for i in range(len(X)):\n",
    "            files.append(np.concatenate(np.array([read_file(X[i] + '_' + str(j) + '.png') \n",
    "                          for j in range(16)])))\n",
    "        self.x = files\n",
    "        \n",
    "        masks = []\n",
    "        for i in range(len(X)):\n",
    "            masks.append(np.concatenate(np.array([get_mask(X[i] + '_' + str(j) + '.png') \n",
    "                          for j in range(16)])))\n",
    "        self.y = masks\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "train_ds = PANDADataset(X_train, y_train)\n",
    "valid_ds = PANDADataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be (batch_size, channel, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_dl))\n",
    "x = torch.tensor(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(1,3,2048,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa5d4c7c588>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y.squeeze(0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 2048, 128])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dconv_down1 = double_conv(3, 64)\n",
    "x = dconv_down1(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 1024, 64])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxpool = nn.MaxPool2d(2)\n",
    "x = maxpool(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 1024, 64])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dconv_down2 = double_conv(64, 128)\n",
    "x = dconv_down2(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 512, 32])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = maxpool(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://github.com/usuyama/pytorch-unet/blob/master/pytorch_unet.py\n",
    "\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )   \n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(3, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "        \n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "        #self.fc = nn.Linear(n_class, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float().cuda()\n",
    "        x = x.view(1,3,2048,128) #batch size, channels, height, width\n",
    "        \n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        \n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_metrics(model):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    for x, y in valid_dl:\n",
    "        x = x.long().cuda()\n",
    "        y = y.long().cuda()\n",
    "        batch = y.shape[0]\n",
    "        out = model(x)\n",
    "        loss = F.cross_entropy(out, y)\n",
    "        sum_loss += batch*(loss.item())\n",
    "        total += batch\n",
    "        pred = torch.argmax(out, axis=1).float()\n",
    "        correct += (pred == y).float().sum().item()\n",
    "    val_loss = sum_loss/total\n",
    "    val_acc = correct/total\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, optimizer, epochs=10):\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total = 0\n",
    "        for x, y in train_dl:\n",
    "            x = x.long().cuda()\n",
    "            y = y.long().cuda()\n",
    "            out = model(x)\n",
    "            #plt.imshow(x.squeeze(0).cpu())\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += x.size(0)*loss.item()\n",
    "            total += x.size(0)\n",
    "        train_loss = total_loss/total\n",
    "        val_loss, val_accuracy = valid_metrics(model)\n",
    "        \n",
    "        print(\"train_loss %.3f val_loss %.3f val_accuracy %.3f\" % (\n",
    "            train_loss, val_loss, val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(6).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 90744390728267137024.000 val_loss 0.944 val_accuracy 164428.027\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "train_epocs(model, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
