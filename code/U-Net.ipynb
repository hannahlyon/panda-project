{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from PIL import Image \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score\n",
       "0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0\n",
       "1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0\n",
       "2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels = pd.read_csv(PATH/'train_labels.csv')\n",
    "test = pd.read_csv(PATH/'test.csv')\n",
    "labels = pd.read_csv(PATH/'train_labels_clean.csv')\n",
    "labels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(labels['image_id'].values, \n",
    "                                                  labels['isup_grade'].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    '''return array representing image'''\n",
    "    return skimage.io.imread(PATH/f'train/{filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_bw(filename):\n",
    "    image_file = Image.open(PATH/f'train/{filename}') # open colour image\n",
    "    image_file = image_file.convert('1') # convert image to black and white\n",
    "    return image_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(filename):\n",
    "    return skimage.io.imread(PATH/f'masks/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PANDADataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        files = []\n",
    "        for i in range(len(X)):\n",
    "            files.append(np.concatenate(np.array([read_file(X[i] + '_' + str(j) + '.png') \n",
    "                          for j in range(16)])))\n",
    "        self.x = files\n",
    "        \n",
    "        masks = []\n",
    "        for i in range(len(X)):\n",
    "            masks.append(np.concatenate(np.array([get_mask(X[i] + '_' + str(j) + '.png') \n",
    "                          for j in range(16)])))\n",
    "        self.y = masks\n",
    "        \n",
    "        self.labels = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx], self.labels[idx]\n",
    "    \n",
    "train_ds = PANDADataset(X_train, y_train)\n",
    "valid_ds = PANDADataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be (batch_size, channel, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x, y, label = next(iter(train_dl))\n",
    "x = torch.tensor(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(1,3,2048,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 128])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f12e15b8f60>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y.squeeze(0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 2048, 128])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dconv_down1 = double_conv(3, 64)\n",
    "x = dconv_down1(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 1024, 64])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxpool = nn.MaxPool2d(2)\n",
    "x = maxpool(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 1024, 64])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dconv_down2 = double_conv(64, 128)\n",
    "x = dconv_down2(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 512, 32])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = maxpool(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://github.com/usuyama/pytorch-unet/blob/master/pytorch_unet.py\n",
    "\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )   \n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(3, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "        \n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "        self.fc = nn.Linear(16777216, n_class)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float().cuda()\n",
    "        x = x.view(1,3,2048,128) #batch size, channels, height, width\n",
    "        \n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        \n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        \n",
    "        out1 = self.conv_last(x)\n",
    "        out2 = F.relu(self.fc(torch.flatten(x, start_dim=1)))\n",
    "        \n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_metrics(model):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    for x, y, label in valid_dl:\n",
    "        x = x.long().cuda()\n",
    "        y = y.long().cuda()\n",
    "        label = label.long().cuda()\n",
    "        batch = y.shape[0]\n",
    "        out1, out2 = model(x)\n",
    "        loss = F.cross_entropy(out2, label)\n",
    "        \n",
    "        _, pred = torch.max(out2, 1)\n",
    "        correct += pred.eq(label).sum().item()\n",
    "        sum_loss += loss.item()\n",
    "        total += batch\n",
    "\n",
    "    val_loss = sum_loss/total\n",
    "    val_acc = correct/total\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, optimizer, epochs=10):\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total = 0\n",
    "        for x, y, label in train_dl:\n",
    "            x = x.long().cuda()\n",
    "            y = y.long().cuda()\n",
    "            label = label.long().cuda()\n",
    "            out1, out2 = model(x)\n",
    "            #plt.imshow(x.squeeze(0).cpu())\n",
    "#             print(out1.shape)\n",
    "#             print(out2.shape)\n",
    "#             print(label.shape)\n",
    "            loss = F.cross_entropy(out2, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += x.size(0)*loss.item()\n",
    "            total += x.size(0)\n",
    "        train_loss = total_loss/total\n",
    "        val_loss, val_accuracy = valid_metrics(model)\n",
    "        \n",
    "        print(\"train_loss %.3f val_loss %.3f val_accuracy %.3f\" % (\n",
    "            train_loss, val_loss, val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(6).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1119393.996 val_loss 1.792 val_accuracy 0.281\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "train_epocs(model, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
