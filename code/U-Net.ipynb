{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from PIL import Image \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://github.com/usuyama/pytorch-unet/blob/master/pytorch_unet.py\n",
    "# and https://github.com/yanneta/deep-learning-with-pytorch/blob/master/lesson9-muti-task-fish.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score\n",
       "0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0\n",
       "1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0\n",
       "2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels = pd.read_csv(PATH/'train_labels.csv')\n",
    "test = pd.read_csv(PATH/'test.csv')\n",
    "labels = pd.read_csv(PATH/'train_labels_clean.csv')\n",
    "labels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(labels['image_id'].values, \n",
    "                                                  labels['isup_grade'].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    '''return array representing image'''\n",
    "    return skimage.io.imread(PATH/f'train/{filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_bw(filename):\n",
    "    image_file = Image.open(PATH/f'train/{filename}') # open colour image\n",
    "    image_file = image_file.convert('1') # convert image to black and white\n",
    "    return image_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(filename):\n",
    "    return skimage.io.imread(PATH/f'masks/{filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PANDADataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        files = []\n",
    "        for i in range(len(X)):\n",
    "            files.append(np.concatenate(np.array([read_file(X[i] + '_' + str(j) + '.png') \n",
    "                          for j in range(16)])))\n",
    "        self.x = files\n",
    "        \n",
    "        masks = []\n",
    "        for i in range(len(X)):\n",
    "            masks.append(np.concatenate(np.array([get_mask(X[i] + '_' + str(j) + '.png') \n",
    "                          for j in range(16)])))\n",
    "        self.y = masks\n",
    "        \n",
    "        self.labels = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx], self.labels[idx]\n",
    "    \n",
    "train_ds = PANDADataset(X_train[:50], y_train[:50])\n",
    "valid_ds = PANDADataset(X_val[:50], y_val[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be (batch_size, channel, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x, y, label = next(iter(train_dl))\n",
    "x = torch.tensor(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(1,3,2048,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 128])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdd91481630>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y.squeeze(0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 2048, 128])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dconv_down1 = double_conv(3, 64)\n",
    "x = dconv_down1(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 1024, 64])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxpool = nn.MaxPool2d(2)\n",
    "x = maxpool(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 1024, 64])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dconv_down2 = double_conv(64, 128)\n",
    "x = dconv_down2(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 512, 32])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = maxpool(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://github.com/usuyama/pytorch-unet/blob/master/pytorch_unet.py\n",
    "\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )   \n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(3, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "        \n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "        self.fc = nn.Linear(16777216, n_class)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float().cuda()\n",
    "        x = x.view(1,3,2048,128) #batch size, channels, height, width\n",
    "        \n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        \n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        \n",
    "        out1 = self.conv_last(x)\n",
    "        out2 = F.relu(self.fc(torch.flatten(x, start_dim=1)))\n",
    "        \n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_metrics(model):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    for x, y, label in valid_dl:\n",
    "        x = x.long().cuda()\n",
    "        y = y.long().cuda()\n",
    "        label = label.long().cuda()\n",
    "        batch = y.shape[0]\n",
    "        out1, out2 = model(x)\n",
    "        \n",
    "        loss = F.cross_entropy(out2, label)\n",
    "        _, pred = torch.max(out2, 1)\n",
    "        correct += pred.eq(label).sum().item()\n",
    "        sum_loss += loss.item()\n",
    "        total += batch\n",
    "\n",
    "    val_loss = sum_loss/total\n",
    "    val_acc = correct/total\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, optimizer, epochs=10):\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total = 0\n",
    "        for x, y, label in train_dl:\n",
    "            x = x.long().cuda()\n",
    "            y = y.long().cuda()\n",
    "            label = label.long().cuda()\n",
    "            out1, out2 = model(x)\n",
    "            \n",
    "#             loss = F.cross_entropy(out2, label)\n",
    "\n",
    "            loss_class = F.cross_entropy(out2, label)\n",
    "#             print(out1.shape)\n",
    "#             print(y.shape)\n",
    "            loss_mask = F.l1_loss(out1.squeeze(0), y, reduction=\"none\").sum(1)\n",
    "            loss_mask = loss_mask.sum()\n",
    "            loss = loss_class + loss_mask/1000\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += x.size(0)*loss.item()\n",
    "            total += x.size(0)\n",
    "        train_loss = total_loss/total\n",
    "        val_loss, val_accuracy = valid_metrics(model)\n",
    "        \n",
    "        print(\"train_loss %.3f val_loss %.3f val_accuracy %.3f\" % (\n",
    "            train_loss, val_loss, val_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 132.047 val_loss 0.005 val_accuracy 0.240\n",
      "train_loss 132.522 val_loss 0.039 val_accuracy 0.240\n",
      "train_loss 132.515 val_loss 0.008 val_accuracy 0.240\n",
      "train_loss 132.503 val_loss 0.024 val_accuracy 0.240\n",
      "train_loss 132.645 val_loss 0.019 val_accuracy 0.240\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_epocs(model, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type UNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, '../models/unet_1.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
