{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Image augmentation\n",
    "from albumentations import Compose, Normalize, HorizontalFlip, VerticalFlip\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from skimage import io\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>This way we can call models and model inputs <>.to(device) and have it work regardless if on cpu or gpu</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.hub.set_dir('/home/ubuntu/prostate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Seen a lot of people on Kaggle set all seeds in one place </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_torch(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "batch_size = 8\n",
    "N = 10  # number of tiles per image\n",
    "\n",
    "# Need to change if putting onto a Kaggle kernel?\n",
    "TRAIN = '../data/tiles_data/train'\n",
    "LABELS = '../data/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(LABELS).set_index('image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10616, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0005f7aaab2800f6170c399693a96917</th>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000920ad0b612851f8e01bcc880d9b3d</th>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0018ae58b01bdadc8e347995b69f99aa</th>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001c62abd11fa4b57bf7a6c603a11bb9</th>\n",
       "      <td>karolinska</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001d865e65ef5d2579c190a0e0350d8f</th>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 data_provider  isup_grade gleason_score\n",
       "image_id                                                                \n",
       "0005f7aaab2800f6170c399693a96917    karolinska           0           0+0\n",
       "000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0\n",
       "0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4\n",
       "001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4           4+4\n",
       "001d865e65ef5d2579c190a0e0350d8f    karolinska           0           0+0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"> Should check at some point if test set has similar distribution of target labels. Thought I saw in paper that test set was more heavily biased towards Grade 5 images...</>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2892\n",
       "1    2666\n",
       "2    1343\n",
       "4    1249\n",
       "3    1242\n",
       "5    1224\n",
       "Name: isup_grade, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isup_grade.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only consider images we have processed and stored as tiles in TRAIN folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = {filepath[:32] for filepath in os.listdir(TRAIN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[image_ids]\n",
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lose about 100 images (from IAFoss pre-processing, he only used images with masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10516, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_idxs = np.random.choice(len(data), 500, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_data = data.iloc[subset_idxs].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(data, test_size=0.3, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True, drop=True)\n",
    "valid.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1d5d638e25521b927dd533db4fadbd46</td>\n",
       "      <td>radboud</td>\n",
       "      <td>2</td>\n",
       "      <td>3+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4932f17e88988f2e6ce80c1fe627f390</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d11c87201830d5e0b853fe783ff28b70</td>\n",
       "      <td>radboud</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7b8d2f39e387bc0a54504377f8318247</td>\n",
       "      <td>radboud</td>\n",
       "      <td>3</td>\n",
       "      <td>4+3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5d33e6224a522400d7a4bb76e47fcfbf</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>2</td>\n",
       "      <td>3+4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score\n",
       "0  1d5d638e25521b927dd533db4fadbd46       radboud           2           3+4\n",
       "1  4932f17e88988f2e6ce80c1fe627f390    karolinska           0           0+0\n",
       "2  d11c87201830d5e0b853fe783ff28b70       radboud           0      negative\n",
       "3  7b8d2f39e387bc0a54504377f8318247       radboud           3           4+3\n",
       "4  5d33e6224a522400d7a4bb76e47fcfbf    karolinska           2           3+4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileTrainDataSet(Dataset):\n",
    "    def __init__(self, df, transform_fn=None):\n",
    "        self.X = df['image_id']\n",
    "        self.Y = df['isup_grade']\n",
    "        self.transform = transform_fn\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Take image id and use the first N tiles (all have the same target label)\n",
    "        img_id = self.X[idx]\n",
    "        imgs = []\n",
    "        for i in range(N):\n",
    "            img = io.imread(os.path.join(TRAIN,img_id+f\"_{i}.png\"))\n",
    "            \n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=img)\n",
    "                img = augmented['image']\n",
    "            imgs.append(img)\n",
    "        # Final shape is x:  N x 3 x 128 x 128, y: 1\n",
    "        x = torch.stack(imgs)\n",
    "        return x, self.Y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_transforms(*, partition):\n",
    "    \n",
    "    assert partition in ('train', 'valid')\n",
    "    \n",
    "    if partition == 'train':\n",
    "        return Compose([\n",
    "            HorizontalFlip(p=0.5),  # 50/50 chance of performing horizontal flip\n",
    "            VerticalFlip(p=0.5),\n",
    "            # Normalize images according to ResNext specifications\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "    elif partition == 'valid':\n",
    "        # Don't flip validation data \n",
    "        return Compose([\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TileTrainDataSet(train, transform_fn=img_transforms(partition='train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = TileTrainDataSet(valid, transform_fn=img_transforms(partition='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    # n=6 represents number of label classes, give better name. \n",
    "    # Except for now doing regression instead of classification\n",
    "    def __init__(self, arch='resnext50_32x4d_ssl', n=6, pre=True):\n",
    "        super().__init__()\n",
    "        m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', arch)\n",
    "        self.enc = nn.Sequential(*list(m.children())[:-2])  # Remove last two layers from ResNext\n",
    "        nc = list(m.children())[-1].in_features  # 2048 (last linear layer of resnext50)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.linear1 = nn.Linear(nc,1)\n",
    "        #self.bn = nn.BatchNorm1d(512)\n",
    "        #self.dropout = nn.Dropout(0.5)\n",
    "        #self.linear2 = nn.Linear(512,1)\n",
    "                                 \n",
    "    def forward(self, x):\n",
    "        # Original shape: bs x N x 3 x 128 x 128\n",
    "        shape = x.shape\n",
    "        x = x.view(-1,shape[2],shape[3],shape[4])  # bs*N x 3 x 128 x 128\n",
    "        # C represents output_size from ResNext\n",
    "        x = self.enc(x)  # bs*N x C x 4 x 4\n",
    "        \n",
    "        shape = x.shape\n",
    "        # concatenate the output for tiles into a single map\n",
    "        # Need to do in two steps to 1) Separate batch_size and N, 2) Combine N into outer dimensions \n",
    "        # Result: bs x C x N*4 x 4\n",
    "        x = x.view(-1,N,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous()\\\n",
    "          .view(-1,shape[1],shape[2]*N,shape[3])  \n",
    "        \n",
    "        # With 2-D pooling over size 1, reduces last two dimensions to 1 \n",
    "        x = self.pool(x)  # bs x C x 1 x 1\n",
    "        # Flatten last three dimensions (result: bs x C)\n",
    "        x = self.linear1(torch.flatten(x, start_dim=1)) \n",
    "        #x = self.bn(x)\n",
    "        #x = self.dropout(x)\n",
    "        #x = self.linear2(x)\n",
    "        # Look at other pre-trained models intended for regression?\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_dl, epochs,):\n",
    "    iterations = epochs*len(train_dl)\n",
    "    pbar = tqdm_notebook(total=iterations)\n",
    "    best_kappa = 0.0\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total = 0\n",
    "\n",
    "        for img, label in train_dl:\n",
    "            img = img.to(device)\n",
    "            label = label.to(device).float().unsqueeze(1)\n",
    "            out = model(img)\n",
    "            # some suggest since kappa is a quasi-measure of \"distance\" from true label, \n",
    "            # better to calculate MSE regression loss than classification loss\n",
    "            loss = F.mse_loss(out, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += label.size(0)*loss.item()\n",
    "            total += label.size(0)\n",
    "            pbar.update()\n",
    "        train_loss = total_loss/total\n",
    "        val_loss, val_kappa = valid_metrics(model, valid_dl)\n",
    "        print(f\"train_loss {train_loss:.3f} val_loss {val_loss:.3f} val_kappa {val_kappa:.3f}\")\n",
    "        if val_kappa > best_kappa:\n",
    "            best_kappa = val_kappa\n",
    "            save_model(model, f\"../models/model_{best_kappa:.3f}.pth\")\n",
    "            print(f\"New best model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_metrics(model, valid_dl):\n",
    "    iterations = len(valid_dl)\n",
    "    pbar = tqdm_notebook(total=iterations)\n",
    "    \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for img, label in valid_dl:\n",
    "        img = img.to(device)\n",
    "        batch = label.shape[0]\n",
    "        out = model(img)\n",
    "        loss = F.mse_loss(out, label.to(device).float().unsqueeze(1))\n",
    "        total_loss += batch*(loss.item())\n",
    "        total += batch\n",
    "        \n",
    "        preds.append(out.detach().to('cpu').apply_(threshold).long().numpy())\n",
    "        labels.append(label.long().numpy())\n",
    "        pbar.update()\n",
    "        \n",
    "    val_loss = total_loss/total\n",
    "    val_kappa = cohen_kappa_score(np.concatenate(preds), np.concatenate(labels).reshape(-1,1), weights='quadratic')\n",
    "    return val_loss, val_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(x):\n",
    "    return max(\n",
    "                min(round(x),5)\n",
    "            ,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ubuntu/prostate/facebookresearch_semi-supervised-ImageNet1K-models_master\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6989da3ec0b241debc43cfa906c26494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2763.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b76690015940ecb6994a1f6b6cee97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=395.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.938 val_loss 1.775 val_kappa 0.657\n",
      "New best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df7b969c0d745b8aa6052bd8a5f3fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=395.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.706 val_loss 1.421 val_kappa 0.656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f283367d9e64a328eae679fb48d0343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=395.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.622 val_loss 1.474 val_kappa 0.633\n"
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer, train_dl, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by Step Run Through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(-1, shape[2], shape[3], shape[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.enc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to do in two steps so: 1) tiles are separated (320 into 32 & 10), 2) tiles combined into 2nd dimension (10*4)\n",
    "x = x.view(-1,N,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous()\\\n",
    "          .view(-1,shape[1],shape[2]*N,shape[3])          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.pool(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.flatten(x, start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.linear1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.bn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.linear2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
