{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code based on https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce\n",
    "# and https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "# and https://github.com/yanneta/deep-learning-with-pytorch/blob/master/lesson7-transfer-learning-v0.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from PIL import Image \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(PATH/'test.csv')\n",
    "labels = pd.read_csv(PATH/'train_labels_clean.csv')\n",
    "labels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(labels['image_id'].values, \n",
    "                                                  labels['isup_grade'].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    '''return array representing image'''\n",
    "    return skimage.io.imread(PATH/f'train/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(filename):\n",
    "    return skimage.io.imread(PATH/f'masks/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PANDADataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        files = []\n",
    "        for i in range(len(X)):\n",
    "            files.append(np.concatenate(np.array([read_file(X[i] + '_' + str(j) + '.png') \n",
    "                          for j in range(16)])))\n",
    "        self.x = files\n",
    "        \n",
    "        masks = []\n",
    "        for i in range(len(X)):\n",
    "            masks.append(np.concatenate(np.array([get_mask(X[i] + '_' + str(j) + '.png') \n",
    "                          for j in range(16)])))\n",
    "        self.y = masks\n",
    "        \n",
    "        self.labels = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx], self.labels[idx]\n",
    "    \n",
    "train_ds = PANDADataset(X_train[:50], y_train[:50])\n",
    "valid_ds = PANDADataset(X_val[:50], y_val[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, labels = next(iter(train_dl))\n",
    "x.shape, y.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.vgg16(pretrained=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[6] = nn.Sequential(\n",
    "                      nn.Linear(n_inputs, 256), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(256, n_classes),                   \n",
    "                      nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = F.cross_entropy()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, n_epochs)\n",
    "    for epoch in range(n_epochs):\n",
    "        val_loss = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for x, y, labels in trainloader:\n",
    "            # Generate predictions\n",
    "            out = model(x)\n",
    "            # Calculate loss\n",
    "            loss = criterion(out, labels)\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            # Update model parameters\n",
    "            optimizer.step()\n",
    "        for x, y, labels in validloader:\n",
    "            # Generate predictions \n",
    "            out = model(x)\n",
    "            # Calculate loss\n",
    "            loss = criterion(out, labels)\n",
    "            _, pred = torch.max(out, 1)\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "            total += len(y)\n",
    "            val_loss += loss\n",
    "\n",
    "        # Average validation loss\n",
    "        val_loss = val_loss / len(trainloader)\n",
    "        print('val_loss:', val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, criterion, optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
